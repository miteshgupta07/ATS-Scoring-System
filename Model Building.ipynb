{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from spacy.util import filter_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/train/train_data.json','rb') as f:\n",
    "    train_data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blank English NLP model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create the NER component and add it to the pipeline\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add labels to the NER component\n",
    "for item in train_data:\n",
    "    for _, _, label in item['entities']:\n",
    "        ner.add_label(label)\n",
    "\n",
    "# Prepare training data in the format required by spaCy 3.x\n",
    "train_examples = []\n",
    "count=0\n",
    "for item in train_data:\n",
    "    doc = nlp.make_doc(item[\"text\"])\n",
    "    ents = []\n",
    "    for start, end, label in item['entities']:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is not None:\n",
    "            ents.append(span)\n",
    "    \n",
    "    filtered_ents = filter_spans(ents)\n",
    "    doc.ents = filtered_ents\n",
    "    example = Example.from_dict(doc, {\"entities\": item['entities']})\n",
    "    train_examples.append(example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Losses: 26612.209, Precision: 0.997, Recall: 1.000, F1-score: 0.999\n",
      "Iteration 2: Losses: 5704.469, Precision: 0.934, Recall: 1.000, F1-score: 0.966\n",
      "Iteration 3: Losses: 3952.015, Precision: 0.823, Recall: 1.000, F1-score: 0.903\n",
      "Iteration 4: Losses: 3180.710, Precision: 0.900, Recall: 1.000, F1-score: 0.947\n",
      "Iteration 5: Losses: 2740.532, Precision: 0.851, Recall: 1.000, F1-score: 0.919\n",
      "Iteration 6: Losses: 2647.418, Precision: 0.884, Recall: 1.000, F1-score: 0.938\n",
      "Iteration 7: Losses: 2200.027, Precision: 0.885, Recall: 1.000, F1-score: 0.939\n",
      "Iteration 8: Losses: 2086.462, Precision: 0.881, Recall: 1.000, F1-score: 0.937\n",
      "Iteration 9: Losses: 1896.823, Precision: 0.893, Recall: 1.000, F1-score: 0.944\n",
      "Iteration 10: Losses: 1817.931, Precision: 0.931, Recall: 1.000, F1-score: 0.964\n",
      "Iteration 11: Losses: 1680.189, Precision: 0.936, Recall: 1.000, F1-score: 0.967\n",
      "Iteration 12: Losses: 1707.834, Precision: 0.907, Recall: 1.000, F1-score: 0.951\n",
      "Iteration 13: Losses: 1603.189, Precision: 0.928, Recall: 1.000, F1-score: 0.963\n",
      "Iteration 14: Losses: 1530.553, Precision: 0.931, Recall: 1.000, F1-score: 0.964\n",
      "Iteration 15: Losses: 1418.975, Precision: 0.943, Recall: 1.000, F1-score: 0.970\n",
      "Iteration 16: Losses: 1448.126, Precision: 0.904, Recall: 1.000, F1-score: 0.950\n",
      "Iteration 17: Losses: 1277.593, Precision: 0.947, Recall: 1.000, F1-score: 0.973\n",
      "Iteration 18: Losses: 1275.569, Precision: 0.966, Recall: 1.000, F1-score: 0.983\n",
      "Iteration 19: Losses: 1246.902, Precision: 0.954, Recall: 1.000, F1-score: 0.976\n",
      "Iteration 20: Losses: 1147.991, Precision: 0.890, Recall: 1.000, F1-score: 0.942\n",
      "Iteration 21: Losses: 1112.616, Precision: 0.918, Recall: 1.000, F1-score: 0.958\n",
      "Iteration 22: Losses: 980.910, Precision: 0.916, Recall: 1.000, F1-score: 0.956\n",
      "Iteration 23: Losses: 986.483, Precision: 0.909, Recall: 1.000, F1-score: 0.952\n",
      "Iteration 24: Losses: 1034.985, Precision: 0.943, Recall: 1.000, F1-score: 0.970\n",
      "Iteration 25: Losses: 987.256, Precision: 0.945, Recall: 1.000, F1-score: 0.972\n",
      "Iteration 26: Losses: 983.464, Precision: 0.912, Recall: 1.000, F1-score: 0.954\n",
      "Iteration 27: Losses: 987.474, Precision: 0.955, Recall: 1.000, F1-score: 0.977\n",
      "Iteration 28: Losses: 976.155, Precision: 0.957, Recall: 1.000, F1-score: 0.978\n",
      "Iteration 29: Losses: 951.699, Precision: 0.947, Recall: 1.000, F1-score: 0.973\n",
      "Iteration 30: Losses: 851.523, Precision: 0.927, Recall: 1.000, F1-score: 0.962\n",
      "Iteration 31: Losses: 817.878, Precision: 0.969, Recall: 1.000, F1-score: 0.984\n",
      "Iteration 32: Losses: 866.606, Precision: 0.940, Recall: 1.000, F1-score: 0.969\n",
      "Iteration 33: Losses: 823.616, Precision: 0.914, Recall: 1.000, F1-score: 0.955\n",
      "Iteration 34: Losses: 820.650, Precision: 0.950, Recall: 1.000, F1-score: 0.974\n",
      "Iteration 35: Losses: 789.587, Precision: 0.946, Recall: 1.000, F1-score: 0.972\n",
      "Iteration 36: Losses: 763.384, Precision: 0.934, Recall: 1.000, F1-score: 0.966\n",
      "Iteration 37: Losses: 753.573, Precision: 0.962, Recall: 1.000, F1-score: 0.981\n",
      "Iteration 38: Losses: 735.642, Precision: 0.953, Recall: 1.000, F1-score: 0.976\n",
      "Iteration 39: Losses: 694.879, Precision: 0.979, Recall: 1.000, F1-score: 0.989\n",
      "Iteration 40: Losses: 733.312, Precision: 0.970, Recall: 1.000, F1-score: 0.985\n",
      "Iteration 41: Losses: 707.260, Precision: 0.963, Recall: 1.000, F1-score: 0.981\n",
      "Iteration 42: Losses: 686.931, Precision: 0.946, Recall: 1.000, F1-score: 0.972\n",
      "Iteration 43: Losses: 637.460, Precision: 0.956, Recall: 1.000, F1-score: 0.978\n",
      "Iteration 44: Losses: 720.086, Precision: 0.972, Recall: 1.000, F1-score: 0.986\n",
      "Iteration 45: Losses: 602.563, Precision: 0.978, Recall: 1.000, F1-score: 0.989\n",
      "Iteration 46: Losses: 609.871, Precision: 0.955, Recall: 1.000, F1-score: 0.977\n",
      "Iteration 47: Losses: 614.682, Precision: 0.986, Recall: 1.000, F1-score: 0.993\n",
      "Iteration 48: Losses: 593.069, Precision: 0.973, Recall: 1.000, F1-score: 0.986\n",
      "Iteration 49: Losses: 675.111, Precision: 0.960, Recall: 1.000, F1-score: 0.979\n",
      "Iteration 50: Losses: 574.115, Precision: 0.969, Recall: 1.000, F1-score: 0.984\n",
      "Iteration 51: Losses: 574.475, Precision: 0.965, Recall: 1.000, F1-score: 0.982\n",
      "Iteration 52: Losses: 542.209, Precision: 0.964, Recall: 1.000, F1-score: 0.982\n",
      "Iteration 53: Losses: 533.706, Precision: 0.955, Recall: 1.000, F1-score: 0.977\n",
      "Iteration 54: Losses: 607.607, Precision: 0.961, Recall: 1.000, F1-score: 0.980\n",
      "Iteration 55: Losses: 558.791, Precision: 0.982, Recall: 1.000, F1-score: 0.991\n",
      "Iteration 56: Losses: 539.896, Precision: 0.959, Recall: 1.000, F1-score: 0.979\n",
      "Iteration 57: Losses: 531.988, Precision: 0.974, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 58: Losses: 561.542, Precision: 0.978, Recall: 1.000, F1-score: 0.989\n",
      "Iteration 59: Losses: 533.384, Precision: 0.962, Recall: 1.000, F1-score: 0.981\n",
      "Iteration 60: Losses: 516.781, Precision: 0.979, Recall: 1.000, F1-score: 0.989\n",
      "Iteration 61: Losses: 474.448, Precision: 0.961, Recall: 1.000, F1-score: 0.980\n",
      "Iteration 62: Losses: 468.161, Precision: 0.990, Recall: 1.000, F1-score: 0.995\n",
      "Iteration 63: Losses: 502.683, Precision: 0.970, Recall: 1.000, F1-score: 0.985\n",
      "Iteration 64: Losses: 457.712, Precision: 0.974, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 65: Losses: 492.248, Precision: 0.973, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 66: Losses: 501.086, Precision: 0.972, Recall: 1.000, F1-score: 0.986\n",
      "Iteration 67: Losses: 499.547, Precision: 0.976, Recall: 1.000, F1-score: 0.988\n",
      "Iteration 68: Losses: 448.287, Precision: 0.986, Recall: 1.000, F1-score: 0.993\n",
      "Iteration 69: Losses: 450.033, Precision: 0.973, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 70: Losses: 436.626, Precision: 0.974, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 71: Losses: 443.753, Precision: 0.962, Recall: 1.000, F1-score: 0.981\n",
      "Iteration 72: Losses: 452.542, Precision: 0.947, Recall: 1.000, F1-score: 0.973\n",
      "Iteration 73: Losses: 450.764, Precision: 0.984, Recall: 1.000, F1-score: 0.992\n",
      "Iteration 74: Losses: 451.362, Precision: 0.975, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 75: Losses: 391.670, Precision: 0.980, Recall: 1.000, F1-score: 0.990\n",
      "Iteration 76: Losses: 428.624, Precision: 0.971, Recall: 1.000, F1-score: 0.985\n",
      "Iteration 77: Losses: 436.983, Precision: 0.986, Recall: 1.000, F1-score: 0.993\n",
      "Iteration 78: Losses: 443.188, Precision: 0.984, Recall: 1.000, F1-score: 0.992\n",
      "Iteration 79: Losses: 381.292, Precision: 0.985, Recall: 1.000, F1-score: 0.992\n",
      "Iteration 80: Losses: 369.396, Precision: 0.976, Recall: 1.000, F1-score: 0.988\n",
      "Iteration 81: Losses: 371.702, Precision: 0.982, Recall: 1.000, F1-score: 0.991\n",
      "Iteration 82: Losses: 389.415, Precision: 0.983, Recall: 1.000, F1-score: 0.992\n",
      "Iteration 83: Losses: 348.948, Precision: 0.973, Recall: 1.000, F1-score: 0.987\n",
      "Iteration 84: Losses: 380.144, Precision: 0.969, Recall: 1.000, F1-score: 0.984\n",
      "Iteration 85: Losses: 405.729, Precision: 0.965, Recall: 1.000, F1-score: 0.982\n",
      "Iteration 86: Losses: 375.188, Precision: 0.968, Recall: 1.000, F1-score: 0.984\n",
      "Iteration 87: Losses: 387.213, Precision: 0.972, Recall: 1.000, F1-score: 0.986\n",
      "Iteration 88: Losses: 370.844, Precision: 0.985, Recall: 1.000, F1-score: 0.993\n",
      "Iteration 89: Losses: 355.205, Precision: 0.979, Recall: 1.000, F1-score: 0.989\n",
      "Iteration 90: Losses: 360.518, Precision: 0.979, Recall: 1.000, F1-score: 0.989\n",
      "Iteration 91: Losses: 357.224, Precision: 0.957, Recall: 1.000, F1-score: 0.978\n",
      "Iteration 92: Losses: 367.662, Precision: 0.984, Recall: 1.000, F1-score: 0.992\n",
      "Iteration 93: Losses: 344.491, Precision: 0.985, Recall: 1.000, F1-score: 0.992\n",
      "Iteration 94: Losses: 354.471, Precision: 0.983, Recall: 1.000, F1-score: 0.991\n",
      "Iteration 95: Losses: 307.208, Precision: 0.980, Recall: 1.000, F1-score: 0.990\n",
      "Iteration 96: Losses: 319.637, Precision: 0.970, Recall: 1.000, F1-score: 0.985\n"
     ]
    }
   ],
   "source": [
    "# Initialize the optimizer\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# Training loop\n",
    "n_iter = 300\n",
    "for itn in range(n_iter):\n",
    "    random.shuffle(train_examples)\n",
    "    losses = {}\n",
    "    # Batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(train_examples, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        nlp.update(\n",
    "            batch,  # batch of Example objects\n",
    "            drop=0.2,  # dropout - make it harder to memorise data\n",
    "            sgd=optimizer,  # callable to update weights\n",
    "            losses=losses\n",
    "        )\n",
    "    scores = nlp.evaluate(train_examples)\n",
    "    ents_p = scores[\"ents_p\"]\n",
    "    ents_r = scores[\"ents_r\"]\n",
    "    ents_f = scores[\"ents_f\"]\n",
    "\n",
    "    print(f\"Iteration {itn+1}: Losses: {losses['ner']:.3f}, Precision: {ents_p:.3f}, Recall: {ents_r:.3f}, F1-score: {ents_f:.3f}\")\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(\"ner_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
