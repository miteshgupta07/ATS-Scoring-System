{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Required Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from spacy.util import filter_spans\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Loading Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pickle.load(open(\"data\\\\train\\\\train_data.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Building the Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:00<00:01, 97.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (1435, 1480, Email Address)\n",
      "Skipping entity: (2022, 2061, Email Address)\n",
      "Skipping entity: (1210, 1247, Email Address)\n",
      "Skipping entity: (1394, 1437, Email Address)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [00:00<00:01, 86.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (1358, 1400, Email Address)\n",
      "Skipping entity: (1089, 1093, Graduation Year)\n",
      "Skipping entity: (1027, 1031, Graduation Year)\n",
      "Skipping entity: (389, 393, Graduation Year)\n",
      "Skipping entity: (1704, 1746, Email Address)\n",
      "Skipping entity: (1656, 1698, Email Address)\n",
      "Skipping entity: (1754, 1792, Email Address)\n",
      "Skipping entity: (1085, 1125, Email Address)\n",
      "Skipping entity: (210, 213, Skills)\n",
      "Skipping entity: (203, 207, Skills)\n",
      "Skipping entity: (50, 56, Companies worked at)\n",
      "Skipping entity: (1586, 1592, Companies worked at)\n",
      "Skipping entity: (2176, 2215, Email Address)\n",
      "Skipping entity: (3996, 3999, Skills)\n",
      "Skipping entity: (2109, 2151, Email Address)\n",
      "Skipping entity: (1341, 1384, Email Address)\n",
      "Skipping entity: (1192, 1234, Email Address)\n",
      "Skipping entity: (1667, 1705, Email Address)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [00:00<00:01, 94.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (265, 307, Email Address)\n",
      "Skipping entity: (2211, 2254, Email Address)\n",
      "Skipping entity: (1801, 1842, Email Address)\n",
      "Skipping entity: (4067, 4069, Skills)\n",
      "Skipping entity: (3812, 3814, Skills)\n",
      "Skipping entity: (1077, 1120, Email Address)\n",
      "Skipping entity: (4167, 4176, Companies worked at)\n",
      "Skipping entity: (1865, 1868, Skills)\n",
      "Skipping entity: (3111, 3152, Email Address)\n",
      "Skipping entity: (1454, 1499, Email Address)\n",
      "Skipping entity: (1945, 1989, Email Address)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 96/200 [00:01<00:01, 102.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (3847, 3851, Graduation Year)\n",
      "Skipping entity: (2272, 2316, Email Address)\n",
      "Skipping entity: (1708, 1752, Email Address)\n",
      "Skipping entity: (61, 106, Email Address)\n",
      "Skipping entity: (2088, 2132, Email Address)\n",
      "Skipping entity: (1522, 1566, Email Address)\n",
      "Skipping entity: (872, 911, Email Address)\n",
      "Skipping entity: (1130, 1174, Email Address)\n",
      "Skipping entity: (4901, 4910, Location)\n",
      "Skipping entity: (1811, 1848, Email Address)\n",
      "Skipping entity: (14240, 14249, Companies worked at)\n",
      "Skipping entity: (11438, 11447, Companies worked at)\n",
      "Skipping entity: (2999, 3043, Email Address)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [00:01<00:00, 154.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (1576, 1580, Location)\n",
      "Skipping entity: (1563, 1608, Email Address)\n",
      "Skipping entity: (0, 4, Location)\n",
      "Skipping entity: (368, 409, Email Address)\n",
      "Skipping entity: (2474, 2514, Email Address)\n",
      "Skipping entity: (2284, 2288, Graduation Year)\n",
      "Skipping entity: (1573, 1578, Graduation Year)\n",
      "Skipping entity: (4729, 4733, Graduation Year)\n",
      "Skipping entity: (2684, 2688, Location)\n",
      "Skipping entity: (863, 868, Location)\n",
      "Skipping entity: (626, 631, Degree)\n",
      "Skipping entity: (67, 72, Location)\n",
      "Skipping entity: (283, 327, Email Address)\n",
      "Skipping entity: (2396, 2399, Degree)\n",
      "Skipping entity: (1338, 1345, Location)\n",
      "Skipping entity: (8133, 8136, Degree)\n",
      "Skipping entity: (8133, 8136, Degree)\n",
      "Skipping entity: (2392, 2434, Email Address)\n",
      "Skipping entity: (5457, 5461, Graduation Year)\n",
      "Skipping entity: (4215, 4219, Graduation Year)\n",
      "Skipping entity: (971, 1015, Email Address)\n",
      "Skipping entity: (872, 875, Degree)\n",
      "Skipping entity: (1234, 1277, Email Address)\n",
      "Skipping entity: (3108, 3150, Email Address)\n",
      "Skipping entity: (2177, 2180, Degree)\n",
      "Skipping entity: (5268, 5272, Location)\n",
      "Skipping entity: (4490, 4494, Location)\n",
      "Skipping entity: (5840, 5847, Companies worked at)\n",
      "Skipping entity: (2090, 2137, Email Address)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 186/200 [00:01<00:00, 131.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (363, 411, Email Address)\n",
      "Skipping entity: (1305, 1347, Email Address)\n",
      "Skipping entity: (1584, 1588, Graduation Year)\n",
      "Skipping entity: (2080, 2086, Degree)\n",
      "Skipping entity: (1094, 1134, Email Address)\n",
      "Skipping entity: (3660, 3664, Graduation Year)\n",
      "Skipping entity: (3539, 3545, Degree)\n",
      "Skipping entity: (2105, 2148, Email Address)\n",
      "Skipping entity: (2198, 2239, Email Address)\n",
      "Skipping entity: (2178, 2223, Email Address)\n",
      "Skipping entity: (1334, 1377, Email Address)\n",
      "Skipping entity: (998, 1038, Email Address)\n",
      "Skipping entity: (277, 328, Email Address)\n",
      "Skipping entity: (1308, 1349, Email Address)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 116.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity: (1369, 1413, Email Address)\n",
      "Skipping entity: (937, 980, Email Address)\n",
      "Skipping entity: (523, 562, Email Address)\n",
      "Skipping entity: (2163, 2205, Email Address)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a blank English NLP model\n",
    "nlp = spacy.blank('en')\n",
    "doc_bin = DocBin()\n",
    "\n",
    "# Iterate through the training data\n",
    "for text, annotations in tqdm(train_data):\n",
    "    # Create a Doc object\n",
    "    doc = nlp.make_doc(text)\n",
    "    \n",
    "    # Create spans for the entities\n",
    "    ents = []\n",
    "    for start, end, label in annotations['entities']:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(f\"Skipping entity: ({start}, {end}, {label})\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    \n",
    "    # Filter overlapping spans\n",
    "    filtered_ents = filter_spans(ents)\n",
    "    \n",
    "    # Set the filtered entities in the Doc\n",
    "    doc.ents = filtered_ents\n",
    "    \n",
    "    # Add the Doc to the DocBin\n",
    "    doc_bin.add(doc)\n",
    "\n",
    "# Save the DocBin to disk\n",
    "doc_bin.to_disk('train.spacy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "\u001b[38;5;3m⚠ Aborting and saving the final best model. Encountered exception:\n",
      "ValueError(\"[E024] Could not find an optimal move to supervise the parser.\n",
      "Usually, this means that the model can't be updated in a way that's valid and\n",
      "satisfies the correct annotations specified in the GoldParse. For example, are\n",
      "all labels added to the model? If you're training a named entity recognizer,\n",
      "also make sure that none of your annotated entity spans have leading or trailing\n",
      "whitespace or punctuation. You can also use the `debug data` command to validate\n",
      "your JSON-formatted training data. For details, run:\\npython -m spacy debug data\n",
      "--help\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\cli\\_util.py\", line 87, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\click\\core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\typer\\core.py\", line 723, in main\n",
      "    return _main(\n",
      "           ^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\typer\\core.py\", line 193, in _main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\click\\core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\click\\core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\click\\core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\typer\\main.py\", line 692, in wrapper\n",
      "    return callback(**use_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\cli\\train.py\", line 54, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\cli\\train.py\", line 84, in train\n",
      "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\loop.py\", line 135, in train\n",
      "    raise e\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\loop.py\", line 118, in train\n",
      "    for batch, info, is_best_checkpoint in training_step_iterator:\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\loop.py\", line 220, in train_while_improving\n",
      "    nlp.update(\n",
      "  File \"c:\\Users\\Mitesh Gupta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py\", line 1193, in update\n",
      "    proc.update(examples, sgd=None, losses=losses, **component_cfg[name])  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"spacy\\pipeline\\transition_parser.pyx\", line 411, in spacy.pipeline.transition_parser.Parser.update\n",
      "  File \"spacy\\pipeline\\transition_parser.pyx\", line 676, in spacy.pipeline.transition_parser.Parser._init_gold_batch\n",
      "  File \"spacy\\pipeline\\_parser_internals\\transition_system.pyx\", line 133, in spacy.pipeline._parser_internals.transition_system.TransitionSystem.get_oracle_sequence_from_state\n",
      "ValueError: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\n",
      "python -m spacy debug data --help\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy train config.cfg --output ./ --paths.train ./train.spacy --paths.dev ./train.spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
